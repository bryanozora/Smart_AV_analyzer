{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1E51qy2VsBZ",
        "outputId": "15926a7f-79e6-4a80-cd1a-9db22fb577b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaJhNieisaaT"
      },
      "outputs": [],
      "source": [
        "# !pip install pyannote.audio==3.1.1 yt-dlp faster-whisper --quiet\n",
        "\n",
        "# !apt-get -qq install -y ffmpeg\n",
        "\n",
        "# # !pip install --upgrade --force-reinstall torch==2.1.2 torchaudio==2.1.2 torchvision==0.16.2 --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# !pip install numpy==1.26.4 --quiet\n",
        "\n",
        "# # !pip install -U --quiet transformers==4.40.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSVnG76_9HB-"
      },
      "outputs": [],
      "source": [
        "# !pip uninstall -y nvidia-cudnn-cu12 nvidia-cudnn-cu11\n",
        "\n",
        "# !pip install --quiet --upgrade --index-url https://download.pytorch.org.whl/cu118 torch==2.2.2+cu118 torchaudio==2.2.2+cu118\n",
        "\n",
        "# !pip install --no-deps pyannote.audio==3.1.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "qbfgl2--r14P"
      },
      "outputs": [],
      "source": [
        "# !pip install --quiet numpy==1.26.4\n",
        "\n",
        "# !pip install --quiet faster_whisper pyannote.audio==3.1.1 yt-dlp\n",
        "\n",
        "# !apt-get -qq install -y ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3wIvPxKJcA9",
        "outputId": "70e7b65c-602a-4329-ea8f-c79005549e6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m480.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.3/174.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m109.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.7/208.7 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m125.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.3/35.3 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.1/821.1 kB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.9/125.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m864.1/864.1 kB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m962.6/962.6 kB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.4/825.4 kB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.7/242.7 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.6/118.6 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "peft 0.15.2 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.22.2 which is incompatible.\n",
            "diffusers 0.34.0 requires huggingface-hub>=0.27.0, but you have huggingface-hub 0.22.2 which is incompatible.\n",
            "gradio 5.31.0 requires huggingface-hub>=0.28.1, but you have huggingface-hub 0.22.2 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.40.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m✅ Semua dependensi berhasil diinstal dengan versi yang kompatibel.\n"
          ]
        }
      ],
      "source": [
        "# Langkah 1: Instal PyTorch versi spesifik yang stabil.\n",
        "!pip install --quiet torch==2.1.2 torchaudio==2.1.2 torchvision==0.16.2 --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Langkah 2: Instal semua library lain dengan versi yang sudah divalidasi kompatibel.\n",
        "# KUNCI PERBAIKAN: menaikkan versi huggingface-hub ke 0.22.2\n",
        "!pip install --quiet \\\n",
        "    numpy==1.26.4 \\\n",
        "    pyannote.audio==3.1.1 \\\n",
        "    faster-whisper \\\n",
        "    yt-dlp \\\n",
        "    datasets \\\n",
        "    sentencepiece \\\n",
        "    accelerate \\\n",
        "    evaluate \\\n",
        "    rouge_score \\\n",
        "    transformers==4.40.1 \\\n",
        "    tokenizers==0.19.1 \\\n",
        "    huggingface-hub==0.22.2\n",
        "\n",
        "# Langkah 3: Instal ffmpeg.\n",
        "!apt-get -qq install -y ffmpeg\n",
        "\n",
        "print(\"✅ Semua dependensi berhasil diinstal dengan versi yang kompatibel.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFQUm5H-WBCQ",
        "outputId": "d00f58c8-8cc4-47d4-b468-3627bd7dc606"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pyannote/audio/core/io.py:43: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
            "  torchaudio.set_audio_backend(\"soundfile\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import gc\n",
        "from datetime import timedelta\n",
        "from huggingface_hub import login\n",
        "from faster_whisper import WhisperModel\n",
        "from pyannote.audio import Pipeline\n",
        "from transformers import pipeline as hf_pipeline\n",
        "from google.colab import files\n",
        "\n",
        "HUGGINGFACE_TOKEN = \"input token hugginface disini\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Path untuk file-file sementara yang akan dibuat oleh skrip\n",
        "TEMP_AUDIO_PATH = \"temp_processing_audio.wav\"\n",
        "OUTPUT_VIDEO_PATH = \"output_with_subtitles.mp4\"\n",
        "SUBTITLE_PATH = \"subtitles.srt\"\n",
        "DEFAULT_INPUT_VIDEO_NAME = \"input_video.mp4\"\n",
        "\n",
        "# Login ke Hugging Face\n",
        "login(token=HUGGINGFACE_TOKEN, add_to_git_credential=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rpDqTNZsmTk"
      },
      "outputs": [],
      "source": [
        "def preprocess_media(input_path, audio_output_path):\n",
        "    \"\"\"Mengekstrak audio dari file video/audio dan mengonversinya ke format WAV 16kHz mono.\"\"\"\n",
        "    print(f\"--- Memproses file media: {input_path} ---\")\n",
        "    # Perintah FFmpeg:\n",
        "    # -y: Timpa file output jika sudah ada\n",
        "    # -i: File input\n",
        "    # -vn: Hapus stream video (hanya ambil audio)\n",
        "    # -acodec pcm_s16le: Format audio WAV standar\n",
        "    # -ar 16000: Sample rate 16kHz (standar untuk model speech-to-text)\n",
        "    # -ac 1: Channel audio mono\n",
        "    command = f'ffmpeg -y -i \"{input_path}\" -vn -acodec pcm_s16le -ar 16000 -ac 1 \"{audio_output_path}\"'\n",
        "    os.system(command)\n",
        "    print(f\"--- Audio berhasil diekstrak dan disimpan di {audio_output_path} ---\")\n",
        "    return audio_output_path\n",
        "\n",
        "def transcribe_audio(audio_path):\n",
        "    \"\"\"Mengubah audio menjadi teks menggunakan Faster-Whisper.\"\"\"\n",
        "    transcription_segments = []\n",
        "    try:\n",
        "        print(\"\\n--- Memulai Transkripsi ---\")\n",
        "        # Model 'medium' adalah keseimbangan yang baik antara kecepatan dan akurasi.\n",
        "        # compute_type=\"float16\" mempercepat proses di GPU.\n",
        "        model = WhisperModel(\"medium\", device=device, compute_type=\"default\")\n",
        "        segments, info = model.transcribe(audio_path, beam_size=5)\n",
        "        transcription_segments = list(segments)\n",
        "        print(f\"-> Bahasa terdeteksi: {info.language} (Probabilitas: {info.language_probability:.2f})\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saat transkripsi: {e}\")\n",
        "    finally:\n",
        "        # Membersihkan memori GPU setelah selesai\n",
        "        if 'model' in locals(): del model\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "    print(\"--- Transkripsi Selesai ---\")\n",
        "    return transcription_segments\n",
        "\n",
        "def diarize_speakers(audio_path):\n",
        "    \"\"\"Mengidentifikasi giliran bicara setiap pembicara menggunakan Pyannote.\"\"\"\n",
        "    speaker_turns = []\n",
        "    try:\n",
        "        print(\"\\n--- Memulai Diarisasi Pembicara ---\")\n",
        "        diarization_pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.1\")\n",
        "        diarization_pipeline.to(torch.device(device))\n",
        "        diarization = diarization_pipeline(audio_path)\n",
        "\n",
        "        # Mengambil hasil diarisasi: waktu mulai, waktu selesai, dan label pembicara\n",
        "        for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
        "            speaker_turns.append({'start': turn.start, 'end': turn.end, 'speaker': speaker})\n",
        "        print(f\"-> Diarisasi selesai. Ditemukan {len(diarization.labels())} pembicara.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saat diarisasi: {e}\")\n",
        "    finally:\n",
        "        if 'diarization_pipeline' in locals(): del diarization_pipeline\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "    print(\"--- Diarisasi Selesai ---\")\n",
        "    return speaker_turns\n",
        "\n",
        "def format_time_srt(seconds):\n",
        "    \"\"\"Mengubah detik menjadi format waktu untuk file subtitle (.srt).\"\"\"\n",
        "    td = timedelta(seconds=seconds)\n",
        "    minutes, seconds = divmod(td.seconds, 60)\n",
        "    hours, minutes = divmod(minutes, 60)\n",
        "    milliseconds = td.microseconds // 1000\n",
        "    return f\"{hours:02d}:{minutes:02d}:{seconds:02d},{milliseconds:03d}\"\n",
        "\n",
        "def generate_final_transcript_and_srt(transcription_segments, speaker_turns, srt_path):\n",
        "    \"\"\"Menggabungkan transkrip dan diarisasi, mencetak hasilnya, dan membuat file .srt.\"\"\"\n",
        "    full_transcript_text = \"\"\n",
        "    srt_content = \"\"\n",
        "    srt_index = 1\n",
        "\n",
        "    print(\"\\n--- Hasil Akhir Transkrip dengan Pembicara ---\")\n",
        "\n",
        "    def get_speaker_label(time, turns):\n",
        "        for turn in turns:\n",
        "            if turn['start'] <= time <= turn['end']:\n",
        "                return turn['speaker']\n",
        "        return \"UNKNOWN\"\n",
        "\n",
        "    for segment in transcription_segments:\n",
        "        # Tentukan pembicara berdasarkan titik tengah segmen waktu\n",
        "        mid_time = segment.start + (segment.end - segment.start) / 2\n",
        "        speaker_label = get_speaker_label(mid_time, speaker_turns)\n",
        "\n",
        "        # Teks yang akan ditampilkan di console\n",
        "        line = f\"[{speaker_label}] ({format_time_srt(segment.start)} --> {format_time_srt(segment.end)}): {segment.text.strip()}\"\n",
        "        print(line)\n",
        "\n",
        "        # Gabungkan teks untuk analisis selanjutnya (ringkasan & Q&A)\n",
        "        full_transcript_text += segment.text.strip() + \" \"\n",
        "\n",
        "        # Buat konten untuk file .srt\n",
        "        start_time_str = format_time_srt(segment.start)\n",
        "        end_time_str = format_time_srt(segment.end)\n",
        "        srt_content += f\"{srt_index}\\n\"\n",
        "        srt_content += f\"{start_time_str} --> {end_time_str}\\n\"\n",
        "        srt_content += f\"[{speaker_label}] {segment.text.strip()}\\n\\n\"\n",
        "        srt_index += 1\n",
        "\n",
        "    # Tulis konten ke file .srt\n",
        "    with open(srt_path, 'w', encoding='utf-8') as f:\n",
        "        f.write(srt_content)\n",
        "    print(f\"\\n--- File subtitle telah disimpan di: {srt_path} ---\")\n",
        "\n",
        "    return full_transcript_text.strip()\n",
        "\n",
        "def burn_subtitles_into_video(video_path, subtitle_path, output_video_path):\n",
        "    \"\"\"Menggabungkan file subtitle ke dalam video untuk membuat 'hardsub'.\"\"\"\n",
        "    print(f\"\\n--- Menambahkan subtitle ke video: {video_path} ---\")\n",
        "    # Perintah FFmpeg untuk \"membakar\" subtitle ke video\n",
        "    command = f'ffmpeg -y -i \"{video_path}\" -vf \"subtitles={subtitle_path}\" \"{output_video_path}\"'\n",
        "    os.system(command)\n",
        "    print(f\"--- Video dengan subtitle berhasil dibuat di: {output_video_path} ---\")\n",
        "    print(\"Anda dapat mengunduhnya dari panel file di sebelah kiri.\")\n",
        "\n",
        "####################################\n",
        "# FUNGSI LAMA SUDAH TIDAK DIPAKAI #\n",
        "###################################\n",
        "def perform_text_analysis(text):\n",
        "    \"\"\"Melakukan ringkasan dan tanya jawab pada transkrip lengkap.\"\"\"\n",
        "    print(\"\\n--- Memulai Analisis Teks ---\")\n",
        "\n",
        "    # Summarization\n",
        "    try:\n",
        "        summarizer = hf_pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=device)\n",
        "        # Batasi input untuk model ringkasan agar tidak terlalu panjang\n",
        "        summary_input = text[:4096]\n",
        "        summary = summarizer(summary_input, max_length=150, min_length=50, do_sample=False)\n",
        "        print(\"\\n**Ringkasan Otomatis:**\")\n",
        "        print(summary[0]['summary_text'])\n",
        "    except Exception as e:\n",
        "        print(f\"Error saat meringkas: {e}\")\n",
        "    finally:\n",
        "        if 'summarizer' in locals(): del summarizer\n",
        "        gc.collect(); torch.cuda.empty_cache()\n",
        "\n",
        "    # Question Answering\n",
        "    try:\n",
        "        qa_pipeline = hf_pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\", device=device)\n",
        "        questions = [\n",
        "            \"What is the main topic of the conversation?\",\n",
        "            \"Who are the speakers mentioned by name?\",\n",
        "            \"What is the key advice or conclusion?\"\n",
        "        ]\n",
        "        print(\"\\n**Tanya Jawab Otomatis:**\")\n",
        "        for q in questions:\n",
        "            result = qa_pipeline(question=q, context=text)\n",
        "            answer = result['answer'] if result['score'] > 0.1 else \"Tidak ditemukan jawaban yang relevan.\"\n",
        "            print(f\"\\nQ: {q}\")\n",
        "            print(f\"A: {answer}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saat tanya jawab: {e}\")\n",
        "    finally:\n",
        "        if 'qa_pipeline' in locals(): del qa_pipeline\n",
        "        gc.collect(); torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCZfe4-us1iM"
      },
      "outputs": [],
      "source": [
        "# --- Membersihkan file dari run sebelumnya ---\n",
        "for path in [TEMP_AUDIO_PATH, SUBTITLE_PATH, OUTPUT_VIDEO_PATH, DEFAULT_INPUT_VIDEO_NAME]:\n",
        "    if os.path.exists(path):\n",
        "        os.remove(path)\n",
        "\n",
        "# --- Menu Pilihan Input untuk Pengguna ---\n",
        "# print(\"=====================================================\")\n",
        "# print(\"      SISTEM ANALISIS AUDIO/VIDEO CERDAS      \")\n",
        "# print(\"=====================================================\")\n",
        "# print(\"Pilih metode input:\")\n",
        "# print(\"1: Gunakan link YouTube\")\n",
        "# print(\"2: Unggah file dari komputer (MP4, WAV, MP3, dll.)\")\n",
        "# choice = input(\"Masukkan pilihan Anda (1 atau 2): \")\n",
        "\n",
        "# input_file_path = None\n",
        "# is_video = False\n",
        "\n",
        "# # --- Jalur 1: Proses Link YouTube ---\n",
        "# if choice == '1':\n",
        "#     youtube_url = input(\"Masukkan link YouTube: \")\n",
        "#     if youtube_url:\n",
        "#         print(f\"\\n--- Mengunduh video dari: {youtube_url} ---\")\n",
        "#         # Mengunduh video sebagai MP4 dengan nama file yang konsisten\n",
        "#         os.system(f\"yt-dlp -f 'best[ext=mp4]/best' -o '{DEFAULT_INPUT_VIDEO_NAME}' --quiet '{youtube_url}'\")\n",
        "\n",
        "#         if os.path.exists(DEFAULT_INPUT_VIDEO_NAME):\n",
        "#             input_file_path = DEFAULT_INPUT_VIDEO_NAME\n",
        "#             is_video = True\n",
        "#             print(\"--- Video berhasil diunduh! ---\")\n",
        "#         else:\n",
        "#             print(\"--- GAGAL mengunduh video. Pastikan link valid dan video tidak memiliki batasan umur/privat. ---\")\n",
        "\n",
        "# # --- Jalur 2: Proses Unggah File ---\n",
        "# elif choice == '2':\n",
        "#     print(\"\\n--- Silakan unggah file Anda melalui tombol di bawah ---\")\n",
        "#     uploaded = files.upload()\n",
        "\n",
        "#     if uploaded:\n",
        "#         input_file_path = list(uploaded.keys())[0]\n",
        "#         if input_file_path.lower().endswith(('.mp4', '.mov', '.avi', '.mkv')):\n",
        "#             is_video = True\n",
        "#         print(f\"--- File '{input_file_path}' berhasil diunggah! ---\")\n",
        "#     else:\n",
        "#         print(\"Tidak ada file yang diunggah. Proses dibatalkan.\")\n",
        "\n",
        "# # --- Pilihan tidak valid ---\n",
        "# else:\n",
        "#     print(\"Pilihan tidak valid. Harap jalankan sel lagi dan pilih 1 atau 2.\")\n",
        "\n",
        "\n",
        "# if input_file_path:\n",
        "#     print(\"\\n\\n================= MEMULAI PROSES ANALISIS =================\\n\")\n",
        "\n",
        "#     # 1. Ekstrak Audio dari file input\n",
        "#     audio_path = preprocess_media(input_file_path, TEMP_AUDIO_PATH)\n",
        "\n",
        "#     # 2. Transkripsi\n",
        "#     transcription_segments = transcribe_audio(audio_path)\n",
        "\n",
        "#     if transcription_segments:\n",
        "#         # 3. Diarisasi\n",
        "#         speaker_turns = diarize_speakers(audio_path)\n",
        "\n",
        "#         if speaker_turns:\n",
        "#             # 4. Gabungkan hasil & Buat file .srt\n",
        "#             full_text = generate_final_transcript_and_srt(transcription_segments, speaker_turns, SUBTITLE_PATH)\n",
        "\n",
        "#             # 5. Jika input adalah video, buat video dengan hardsub\n",
        "#             if is_video:\n",
        "#                 burn_subtitles_into_video(input_file_path, SUBTITLE_PATH, OUTPUT_VIDEO_PATH)\n",
        "\n",
        "#             # 6. Lakukan Analisis Teks (Ringkasan & Q&A)\n",
        "#             if full_text:\n",
        "#                 perform_text_analysis(full_text)\n",
        "#         else:\n",
        "#             print(\"\\nPROSES GAGAL: Diarisasi tidak berhasil. Pipeline dihentikan.\")\n",
        "#     else:\n",
        "#         print(\"\\nPROSES GAGAL: Transkripsi tidak menghasilkan output. Pipeline dihentikan.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5HTf-6T1r3y0",
        "outputId": "abf7d0fa-e71a-4c14-a05b-39467abbe953"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading custom model from: /content/drive/MyDrive/flan-t5-dialogsum-finetuned\n",
            "✅ Successfully loaded fine-tuned FLAN-T5 summarization model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-5-3017621351.py:249: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  qa_chat         = gr.Chatbot(label=\"Tanya Jawab Berdasarkan Video\", height=300)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://8e4d1fbbe268b396dc.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://8e4d1fbbe268b396dc.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Mencoba mengunduh dari YouTube: https://www.youtube.com/shorts/Q0BOH_s9gSU ---\n",
            "--- Video berhasil diunduh sebagai input_video.mp4 ---\n",
            "--- Memproses file media: input_video.mp4 ---\n",
            "--- Audio berhasil diekstrak dan disimpan di temp_processing_audio.wav ---\n",
            "\n",
            "--- Memulai Transkripsi ---\n",
            "-> Bahasa terdeteksi: en (Probabilitas: 1.00)\n",
            "--- Transkripsi Selesai ---\n",
            "\n",
            "--- Memulai Diarisasi Pembicara ---\n",
            "-> Diarisasi selesai. Ditemukan 1 pembicara.\n",
            "--- Diarisasi Selesai ---\n",
            "\n",
            "--- Hasil Akhir Transkrip dengan Pembicara ---\n",
            "[SPEAKER_00] (00:00:00,000 --> 00:00:03,840): I don't actually know if Christian Bale did say this, but the quote is,\n",
            "[SPEAKER_00] (00:00:03,840 --> 00:00:05,840): If you have a problem with me, text me.\n",
            "[SPEAKER_00] (00:00:05,840 --> 00:00:09,280): And if you don't have my number, you don't know me well enough to have a problem with me.\n",
            "[SPEAKER_00] (00:00:09,280 --> 00:00:10,320): That is so good.\n",
            "\n",
            "--- File subtitle telah disimpan di: subtitles.srt ---\n",
            "\n",
            "--- Menambahkan subtitle ke video: input_video.mp4 ---\n",
            "--- Video dengan subtitle berhasil dibuat di: output_with_subtitles.mp4 ---\n",
            "Anda dapat mengunduhnya dari panel file di sebelah kiri.\n"
          ]
        }
      ],
      "source": [
        "# =========================================\n",
        "#  GRADIO UI\n",
        "# =========================================\n",
        "import gradio as gr\n",
        "import subprocess, tempfile, json, pathlib, shutil\n",
        "from transformers import pipeline as hf_pipeline\n",
        "import traceback, time\n",
        "import html\n",
        "\n",
        "# --- pipeline ringan utk ringkasan & QA ---\n",
        "# summarizer   = hf_pipeline(\"summarization\", model=\"facebook/bart-large-cnn\",    device=\"cpu\")\n",
        "# qa_pipeline  = hf_pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\", device=\"cpu\")\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "\n",
        "# Gunakan device yang tersedia (GPU jika ada)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Path ke model fine-tuned Anda di Google Drive\n",
        "load_path = \"/content/drive/MyDrive/flan-t5-dialogsum-finetuned\"\n",
        "summary_model = None\n",
        "summary_tokenizer = None\n",
        "\n",
        "# Coba muat model kustom Anda\n",
        "try:\n",
        "    print(f\"Loading custom model from: {load_path}\")\n",
        "    summary_tokenizer = AutoTokenizer.from_pretrained(load_path)\n",
        "    summary_model = AutoModelForSeq2SeqLM.from_pretrained(load_path, trust_remote_code=True).to(device)\n",
        "    print(\"✅ Successfully loaded fine-tuned FLAN-T5 summarization model.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ ERROR: Could not load the model from {load_path}. Error: {e}\")\n",
        "    print(\"   Summarization will be disabled.\")\n",
        "\n",
        "# Muat pipeline untuk Question-Answering (tidak berubah)\n",
        "qa_pipeline  = hf_pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\", device=device)\n",
        "\n",
        "def summarize_with_flan_t5(text, model, tokenizer):\n",
        "    \"\"\"\n",
        "    Menghasilkan ringkasan menggunakan model FLAN-T5 yang telah di-fine-tune.\n",
        "    \"\"\"\n",
        "    if model is None or tokenizer is None:\n",
        "        return \"Summarization model not loaded. Skipping.\"\n",
        "\n",
        "    # 1. Tambahkan prefix yang diperlukan\n",
        "    input_text = \"summarize: \" + text\n",
        "\n",
        "    # 2. Tokenisasi input\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=1024).to(model.device)\n",
        "\n",
        "    # 3. Generate ringkasan\n",
        "    summary_ids = model.generate(**inputs, max_new_tokens=128)\n",
        "\n",
        "    # 4. Decode output\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "# --- util parse .srt → list dict ----------------------------------------------\n",
        "import re\n",
        "def srt_to_dialog_list(srt_path):\n",
        "    dialog = []\n",
        "    with open(srt_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        blocks = re.split(r\"\\n\\s*\\n\", f.read().strip())\n",
        "    for blk in blocks:\n",
        "        lines = blk.splitlines()\n",
        "        if len(lines) < 3:               # nomor + waktu + text\n",
        "            continue\n",
        "        text = \" \".join(lines[2:]).strip()\n",
        "        m = re.match(r\"\\[([^\\]]+)]\\s*(.+)\", text)\n",
        "        speaker, content = (\"UNKNOWN\", text) if not m else m.groups()\n",
        "        dialog.append({\"speaker\": speaker, \"content\": content})\n",
        "    return dialog\n",
        "\n",
        "# --- konversi ke format gr.Chatbot: list[tuple(str,str)] -----------------------\n",
        "def dialog_to_chat_tuples(dialog):\n",
        "    return [(d[\"speaker\"], d[\"content\"]) for d in dialog]\n",
        "\n",
        "\n",
        "def dialog_to_html(dialog):\n",
        "    \"\"\"\n",
        "    Ubah list [{\"speaker\":..,\"content\":..},…] → HTML chat bubble warna-warni.\n",
        "    \"\"\"\n",
        "    palette = [\n",
        "      \"#0d47a1\",  # navy-blue\n",
        "      \"#4a148c\",  # dark-purple\n",
        "      \"#1b5e20\",  # hunter-green\n",
        "      \"#880e4f\",  # wine-red\n",
        "      \"#b71c1c\",  # dark-crimson\n",
        "      \"#004d40\",  # teal-dark\n",
        "      \"#3e2723\",  # espresso-brown\n",
        "      \"#263238\"   # slate-gray\n",
        "    ]\n",
        "    speaker_color = {}\n",
        "    color_idx = 0\n",
        "    lines = []\n",
        "\n",
        "    for d in dialog:\n",
        "        spk = d[\"speaker\"]\n",
        "        if spk not in speaker_color:\n",
        "            speaker_color[spk] = palette[color_idx % len(palette)]\n",
        "            color_idx += 1\n",
        "        color = speaker_color[spk]\n",
        "        text = html.escape(d[\"content\"])\n",
        "        lines.append(\n",
        "            f\"<div style='background:{color};border-radius:8px;padding:8px;\"\n",
        "            f\"margin-bottom:6px;'><strong>{spk}:</strong> {text}</div>\"\n",
        "        )\n",
        "    return \"<div style='font-family:Arial, sans-serif;line-height:1.4;'>\" + \"\\n\".join(lines) + \"</div>\"\n",
        "\n",
        "# --- core wrapper: jalankan pipeline lama --------------------------------------\n",
        "import traceback, time\n",
        "import gradio as gr\n",
        "\n",
        "def run_full_pipeline(youtube_url, uploaded_file, progress=gr.Progress()):\n",
        "    \"\"\"\n",
        "    Jalankan pipeline + debug.\n",
        "    Semua exception ditangkap, dicetak stack-trace, dan dilempar ke UI sebagai gr.Error.\n",
        "    \"\"\"\n",
        "    t0 = time.perf_counter()          # start timer\n",
        "\n",
        "    def log_and_raise(step, err):\n",
        "        \"\"\"Cetak stack trace + lempar error ke Gradio.\"\"\"\n",
        "        print(f\"\\n[DEBUG] ERROR saat {step}: {err}\")\n",
        "        traceback.print_exc()         # full stack di console\n",
        "        raise gr.Error(f\"Gagal di tahap '{step}': {err}\")\n",
        "\n",
        "    # 0. Sumber input\n",
        "    try:\n",
        "        if youtube_url:\n",
        "            progress(0, desc=\"Mengunduh video...\")\n",
        "            print(f\"--- Mencoba mengunduh dari YouTube: {youtube_url} ---\")\n",
        "\n",
        "            # Perintah yt-dlp sebagai list untuk subprocess\n",
        "            command = [\n",
        "                \"yt-dlp\",\n",
        "                \"-f\", \"best[ext=mp4]/best\",\n",
        "                \"-o\", DEFAULT_INPUT_VIDEO_NAME,\n",
        "                youtube_url\n",
        "            ]\n",
        "\n",
        "            # Menggunakan subprocess untuk menangkap output dan error\n",
        "            # Ini akan memberi kita alasan pasti jika gagal\n",
        "            result = subprocess.run(command, capture_output=True, text=True)\n",
        "\n",
        "            # Periksa apakah yt-dlp mengembalikan kode error (returncode bukan 0)\n",
        "            if result.returncode != 0:\n",
        "                # Ambil pesan error spesifik dari stderr\n",
        "                error_message = result.stderr.strip()\n",
        "                # Lemparkan error yang berisi pesan dari yt-dlp\n",
        "                raise RuntimeError(f\"yt-dlp GAGAL. Pesan error dari YouTube: '{error_message}'\")\n",
        "\n",
        "            input_path = DEFAULT_INPUT_VIDEO_NAME\n",
        "            print(f\"--- Video berhasil diunduh sebagai {input_path} ---\")\n",
        "            is_video = True\n",
        "        elif uploaded_file is not None:\n",
        "            input_path = uploaded_file.name\n",
        "            is_video   = input_path.lower().endswith(('.mp4','.mov','.avi','.mkv'))\n",
        "        else:\n",
        "            raise gr.Error(\"Harap isi URL YouTube **atau** unggah file.\")\n",
        "    except Exception as e:\n",
        "        log_and_raise(\"mengunduh/menentukan input\", e)\n",
        "\n",
        "    # 1. Ekstrak audio\n",
        "    try:\n",
        "        progress(0.10, desc=\"Ekstrak audio…\")\n",
        "        audio_path = preprocess_media(input_path, TEMP_AUDIO_PATH)\n",
        "    except Exception as e:\n",
        "        log_and_raise(\"ekstrak audio\", e)\n",
        "\n",
        "    # 2. Transkripsi\n",
        "    try:\n",
        "        progress(0.30, desc=\"Transkripsi…\")\n",
        "        segments = transcribe_audio(audio_path)\n",
        "    except Exception as e:\n",
        "        log_and_raise(\"transkripsi\", e)\n",
        "\n",
        "    # 3. Diarisasi\n",
        "    try:\n",
        "        progress(0.55, desc=\"Diarisasi…\")\n",
        "        turns = diarize_speakers(audio_path)\n",
        "    except Exception as e:\n",
        "        log_and_raise(\"diarisasi\", e)\n",
        "\n",
        "    # 4. Subtitle & dialog list\n",
        "    try:\n",
        "        progress(0.75, desc=\"Generate subtitle…\")\n",
        "        full_text = generate_final_transcript_and_srt(segments, turns, SUBTITLE_PATH)\n",
        "        dialog    = srt_to_dialog_list(SUBTITLE_PATH)\n",
        "    except Exception as e:\n",
        "        log_and_raise(\"generate subtitle\", e)\n",
        "\n",
        "    # 5. Hardsub (opsional)\n",
        "    video_out = None\n",
        "    if is_video:\n",
        "        try:\n",
        "            progress(0.85, desc=\"Render hardsub…\")\n",
        "            burn_subtitles_into_video(input_path, SUBTITLE_PATH, OUTPUT_VIDEO_PATH)\n",
        "            video_out = OUTPUT_VIDEO_PATH\n",
        "        except Exception as e:\n",
        "            log_and_raise(\"render hardsub\", e)\n",
        "\n",
        "    # 6. Ringkasan\n",
        "    # try:\n",
        "    #     progress(0.95, desc=\"Ringkasan…\")\n",
        "    #     summary = summarizer(full_text[:4096], max_length=150, min_length=50, do_sample=False)[0][\"summary_text\"]\n",
        "    # except Exception as e:\n",
        "    #     log_and_raise(\"ringkasan\", e)\n",
        "\n",
        "    # 6. Ringkasan (MODIFIED)\n",
        "    try:\n",
        "        progress(0.95, desc=\"Membuat ringkasan dengan FLAN-T5...\")\n",
        "        # Panggil fungsi peringkasan kustom Anda\n",
        "        summary = summarize_with_flan_t5(full_text, summary_model, summary_tokenizer)\n",
        "    except Exception as e:\n",
        "        log_and_raise(\"ringkasan\", e)\n",
        "\n",
        "    progress(1, desc=f\"Selesai ✓  ({time.perf_counter()-t0:.1f}s)\")\n",
        "    return (\n",
        "        video_out,\n",
        "        dialog_to_chat_tuples(dialog),\n",
        "        summary,\n",
        "        full_text\n",
        "    )\n",
        "\n",
        "# ------------  QA handler (dipanggil setelah pipeline selesai) -----------------\n",
        "def answer_question(history, user_msg, full_text):\n",
        "    if not full_text:\n",
        "        raise gr.Error(\"Jalankan pipeline dulu.\")\n",
        "    result = qa_pipeline(question=user_msg, context=full_text)\n",
        "    ans    = result[\"answer\"] #if result[\"score\"] > 0.1 else \"Maaf, saya tidak menemukan jawaban relevan.\"\n",
        "    history.append((user_msg, ans))\n",
        "    return history, \"\"\n",
        "\n",
        "# ------------------------  BUILD GRADIO UI  ------------------------------------\n",
        "with gr.Blocks(title=\"Smart AV Analyzer\") as demo:\n",
        "    gr.Markdown(\"## 🎙️ Smart Audio/Video Analyzer\")\n",
        "\n",
        "    with gr.Row():\n",
        "        youtube_in = gr.Textbox(label=\"YouTube URL (opsional)\")\n",
        "        file_in    = gr.File(label=\"Upload Video/Audio (opsional)\")\n",
        "\n",
        "    run_btn = gr.Button(\"🚀  Jalankan Analisis\")\n",
        "\n",
        "    with gr.Row():\n",
        "        video_out = gr.Video(label=\"Video + Subtitle\", visible=False)\n",
        "        summary_out = gr.Textbox(label=\"Ringkasan\", lines=8)\n",
        "\n",
        "    transcript_html = gr.HTML(label=\"Transcript Chat\", elem_id=\"transcript-box\")\n",
        "    qa_chat         = gr.Chatbot(label=\"Tanya Jawab Berdasarkan Video\", height=300)\n",
        "    qa_user_in      = gr.Textbox(label=\"Ketik pertanyaan lalu tekan Enter\")\n",
        "\n",
        "    hidden_context  = gr.State(value=\"\")   # menyimpan full_text utk QA\n",
        "\n",
        "    # --- klik RUN: jalankan pipeline & tampilkan hasil ---\n",
        "    def _run_debug(youtube_url, file_obj):\n",
        "        v, dialog_tuples, summary, context = run_full_pipeline(youtube_url, file_obj)\n",
        "        html_view = dialog_to_html(\n",
        "            [{\"speaker\": t[0], \"content\": t[1]} for t in dialog_tuples]\n",
        "        )\n",
        "        return (\n",
        "            gr.update(value=v, visible=bool(v)),\n",
        "            html_view,\n",
        "            summary,\n",
        "            context\n",
        "        )\n",
        "\n",
        "    run_btn.click(\n",
        "        fn=_run_debug,\n",
        "        inputs=[youtube_in, file_in],\n",
        "        outputs=[video_out, transcript_html, summary_out, hidden_context]\n",
        "    )\n",
        "\n",
        "    # --- QA on Enter ---\n",
        "    qa_user_in.submit(\n",
        "        answer_question,\n",
        "        inputs=[qa_chat, qa_user_in, hidden_context],\n",
        "        outputs=[qa_chat, qa_user_in]\n",
        "    )\n",
        "\n",
        "demo.launch(share=True, debug=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}